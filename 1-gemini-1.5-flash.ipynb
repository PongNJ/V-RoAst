{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-Gemini-1.5-flash (details on 08/08/24)\n",
    "This experiment used Gemini 1.5 Flash because it is currently free to use with limitation detials are below:\n",
    "https://ai.google.dev/pricing\n",
    "## Free of charge*\n",
    "### Rate Limits**\n",
    "- 15 RPM (requests per minute)\n",
    "- 1 million TPM (tokens per minute)\n",
    "- 1,500 RPD (requests per day)\n",
    "\n",
    "### Price (input)\n",
    "- Free of charge\n",
    "\n",
    "### Context caching\n",
    "- Free of charge, up to 1 million tokens of storage per hour\n",
    "\n",
    "### Price (output)\n",
    "- Free of charge\n",
    "\n",
    "### Prompts/responses used to improve our products\n",
    "- Yes\n",
    "\n",
    "*Gemini API free tier usage restrictions apply to EEA (including EU), the UK and CH. See Billing FAQs for details.\n",
    "**Specified rate limits are not guaranteed and actual capacity may vary. Apply for an increased maximum rate limit (for paid tier only).\n",
    "\n",
    "For other models from google, e.g. Gemini1.5 pro is avaliable on: https://ai.google.dev/gemini-api/docs\n",
    "It should be simple changing the configuration but please bare in mind there each model has diffent limitations and costs.\n",
    "\n",
    "Information of Vision capbilities of Gemini API is avaliable on: https://ai.google.dev/gemini-api/docs/vision?lang=python\n",
    "\n",
    "Gemini 1.5 Flash has 1M token context window (An analogy for the context window is short term memory. There is a limited amount of information that can be stored in someone's short term memory, and the same is true for generative models.) https://ai.google.dev/gemini-api/docs/long-context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create Your JavaScript File\n",
    "- Open VSCode and navigate to the folder where your project files are located.\n",
    "- If you don't have a project yet, create a new folder and open it in VSCode.\n",
    "2. Create Your JavaScript File\n",
    "- Inside your project folder, create a new JavaScript file, for example, index.js.\n",
    "- Copy and paste the code you provided into index.js.\n",
    "3. Ensure dotenv is Installed\n",
    "In your project folder, open the integrated terminal in VSCode (View > Terminal or by pressing `Ctrl + ``).\n",
    "\n",
    "Run the following command to install the dotenv package, if you haven't already:\n",
    "- npm install dotenv\n",
    "4. Place Your google_key.env File in the Project Directory\n",
    "- Ensure your google_key.env file is in the root directory of your project (the same directory as your index.js file).\n",
    "5. Run the JavaScript File\n",
    "- With your terminal open in VSCode, run the following command to execute your index.js file:\n",
    "6. Check the Output\n",
    "- After running the command, you should see the API keys logged to the terminal, like this:\n",
    "\n",
    "Google API Key 1: key1\n",
    "\n",
    "Google API Key 2: key2\n",
    "\n",
    "Google API Key 3: key3\n",
    "\n",
    "Google API Key 4: key4\n",
    "\n",
    "...\n",
    "\n",
    "//add more here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    #Example of index.js\n",
    "    // Load environment variables from the google_key.env file\n",
    "    require('dotenv').config({ path: 'google_key.env' });\n",
    "\n",
    "    // Access the keys\n",
    "    const apiKey1 = process.env.GOOGLE_API_KEY_1;\n",
    "    const apiKey2 = process.env.GOOGLE_API_KEY_2;\n",
    "    const apiKey3 = process.env.GOOGLE_API_KEY_3;\n",
    "    const apiKey4 = process.env.GOOGLE_API_KEY_4;\n",
    "\n",
    "    // Function to choose an API key (this can be based on any logic you prefer)\n",
    "    function chooseApiKey() {\n",
    "        // Example: Randomly choose one of the API keys\n",
    "        const apiKeys = [apiKey1, apiKey2, apiKey3, apiKey4];\n",
    "        const randomIndex = Math.floor(Math.random() * apiKeys.length);\n",
    "        return apiKeys[randomIndex];\n",
    "    }\n",
    "\n",
    "    // Use the chosen API key\n",
    "    const selectedApiKey = chooseApiKey();\n",
    "    console.log('Selected API Key:', selectedApiKey);\n",
    "\n",
    "    // Example of using the selected API key with your existing configuration\n",
    "    generation_config = { \n",
    "        \"max_output_tokens\": 8192,\n",
    "        \"response_mime_type\": \"application/json\",\n",
    "        \"api_key\": selectedApiKey // Add the selected API key to the configuration\n",
    "    };"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ucesnjo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import PIL.Image\n",
    "import json\n",
    "import google.generativeai as genai\n",
    "from io import StringIO\n",
    "from dotenv import load_dotenv\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2 import service_account\n",
    "import random\n",
    "import typing_extensions as typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv('//google_key.env')\n",
    "\n",
    "# Access the keys\n",
    "api_keys = [\n",
    "    os.getenv('GOOGLE_API_KEY_1'),\n",
    "    os.getenv('GOOGLE_API_KEY_2'),\n",
    "    os.getenv('GOOGLE_API_KEY_3'),\n",
    "    os.getenv('GOOGLE_API_KEY_4'),\n",
    "    os.getenv('GOOGLE_API_KEY_5'),\n",
    "    os.getenv('GOOGLE_API_KEY_6'),\n",
    "    os.getenv('GOOGLE_API_KEY_7'),\n",
    "    os.getenv('GOOGLE_API_KEY_8'),\n",
    "    os.getenv('GOOGLE_API_KEY_9'),\n",
    "    os.getenv('GOOGLE_API_KEY_10'),\n",
    "    os.getenv('GOOGLE_API_KEY_11'),\n",
    "    os.getenv('GOOGLE_API_KEY_12')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instruction (text input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can experiment with 'local_context' and change 'country' as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the local context to the input data\n",
    "country = \"//country//\"\n",
    "local_context = \"//local_context//\"\n",
    "\n",
    "# country and local_context that we used in the experiment\n",
    "country = \"Thailand\"\n",
    "local_context = \"Speed limits in {country} are a set of maximum speeds that apply to all roads in the country. For <Attribute> = 'Speed limit', the maximum limits are as follows: 80 km/h within built-up areas and in Bangkok, 90 km/h outside built-up areas, and 120 km/h on motorways.\\nFor the <Attribute> = 'Motorcycle speed limit', the limits are 80 km/h in Bangkok and other provinces' built-up areas, and 90 km/h on other highways (motorcycles are not allowed on motorways). For the <Attribute> = 'Truck speed limit', the limits are 60 km/h in Bangkok and other provinces' built-up areas, 80 km/h on highways, and 100 km/h on motorways. <Attribute>: Carriageway answer should be Divided carriageway= 'Carriageway A of a divided road'.\\nFor highways in Thailand <Attribute> 'Lane width' is 'Wide \\u22653.25m'. Moreover, <Attribute>: 'Area type' in Bangkok and Phatum thani should be 'Urban'; therefore, <Attribute>: 'Upgrade cost' should be 'High' and <Attribute>: 'Street lighting' should be 'Present' in Bangkok and Phatum thani area.\\nThe common <Attribute>: Roadside severity - driver-side object are 'Safety barrier - concrete' and 'Safety barrier - metal' that should carefully look at the image. The common <Attribute>: Roadside severity - passenger-side object are 'Safety barrier - concrete', 'Safety barrier - metal', 'Deep drainage ditch', 'Rigid sign, post or pole \\u226510cm' and 'Unprotected safety barrier end' that should carefully look at the image. In Thailand highway, there should not be 'No object' for <Attribute>: Roadside severity - passenger-side object and <Attribute>: Roadside severity - driver-side object.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure the json file is in the correct path\n",
    "json_file = './/text//prompts.json'\n",
    "\n",
    "def format_attributes_to_json(json_file, image_id=\"image_id\"):\n",
    "    with open(json_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    formatted_data = {\"image_id\": image_id}\n",
    "    \n",
    "    for attribute in data[\"attributes\"]:\n",
    "        item_name = attribute.get('Item', 'Unknown Item')\n",
    "        categories = [category.get('Category', 'Unknown Category') for category in attribute.get('categories', [])]\n",
    "        formatted_data[item_name] = categories\n",
    "    \n",
    "    return json.dumps(formatted_data, indent=4)\n",
    "output_json = format_attributes_to_json(json_file)\n",
    "\n",
    "\n",
    "prompt_instruction = f\"\"\"\n",
    "You are a road safety assessment coder from the International Road Assessment Programme (iRAP). Your task is to analyse images of road sections taken in {country} and accurately assess 52 road safety attributes. For each attribute, follow these steps:\n",
    "\n",
    "1. Analyse the Image: Examine the road section in the image, focusing on all relevant elements that correspond to the 52 '<Attribute>'s you need to assess.\n",
    "2. Read the <Attribute Description>: For each of the 52 attributes, read the '<Attribute description>' to understand what specific aspect of the image you need to evaluate.\n",
    "3. Refer to Categories: For each attribute, refer to the possible '<Category class>' options provided. If a '<Category description>' is available, read it to understand the specific criteria for each category.\n",
    "4. Select the Most Matching Category: Based on your analysis of the image and understanding of the attribute and category descriptions, select the single <Category class> that best matches what you observe in the image. If multiple categories are equally relevant, choose the category that appears first in the provided list.\n",
    "5. Output the Results in JSON Format: Return the results in JSON format, with each attribute associated with a single <Category class> value that you assess to be the most appropriate based on the image.\n",
    "\n",
    "Local context:\n",
    "Please use <location> to understand the local context. '<driver-side>' and '<passenger-side>' are used throughout the <Attribute> and <Attribute description>. Driver-side refers to the side of the road corresponding with the driver of a vehicle travelling in the direction of the survey, and the passenger-side is the other side. If the country drives on the left (e.g., the UK), the passenger side is on the left of the image, and the driver side is on the right of the image. {local_context}\n",
    "\"\"\"\n",
    "\n",
    "output_format = f\"\"\"\n",
    "Output Format: Return the results in JSON format, where each attribute is associated with a single <Category class> value that best matches your analysis of the image. If multiple categories seem equally relevant, select the category that appears first in the provided list.\n",
    "\n",
    "JSON structure:\n",
    "{output_json}\n",
    "Ensure that each attribute in the JSON output contains only one selected <Category class> that you determine to be the most appropriate based on the image.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path configurations for ThaiRAP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path configurations\n",
    "image_folder_path = './/image//ThaiRAP'\n",
    "csv_file_path = './Validation.csv'\n",
    "save_path = './/result//gemini-1.5-flash_thairap.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path configurations for Mapillary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path configurations\n",
    "image_folder_path = './/image//Mapillary_processed' #used image folder as the image folder path (images were already processed (cropped, resized, and renamed))\n",
    "csv_file_path = './/image//Mapillary_processed//mapillary.csv'\n",
    "save_path = './/result//gemini-1.5-flash_mapillary.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single prompt\n",
    "This mean, in a request/ask VLM on 1 image and its infomation, however, the aim is to get 52 answers ('attributes') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Function to generate a prompt for a single image\n",
    "def generate_single_image_prompt(image_id, df):\n",
    "    row = df[df['image_id'] == int(image_id)]\n",
    "    if not row.empty:\n",
    "        lat = row['Latitude start'].values[0]\n",
    "        lon = row['Longitude start'].values[0]\n",
    "        return f\"<image_id>: {image_id} and <location>: {{{lat},{lon}}}\"\n",
    "    else:\n",
    "        return None \n",
    "\n",
    "# Function to convert JSON to text prompt\n",
    "def json2text(include_attribute_description=True, include_category_description=True):\n",
    "    with open(json_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    attributes = data[\"attributes\"]\n",
    "    formatted_descriptions = []\n",
    "    \n",
    "    for idx, attribute in enumerate(attributes, 1):\n",
    "        item = attribute.get('Item', 'Unknown Item')\n",
    "        attribute_description = attribute.get('Attribute description', 'No description available.')\n",
    "        \n",
    "        if idx > 1:\n",
    "            formatted_descriptions.append(\"\")  # Add a blank line before each new item\n",
    "        \n",
    "        formatted_descriptions.append(f\"{idx}. <Attribute>: {item}\")\n",
    "        if include_attribute_description:\n",
    "            formatted_descriptions.append(f\"<Attribute description>: {attribute_description}\")\n",
    "        \n",
    "        categories_details = []\n",
    "        \n",
    "        for category in attribute.get('categories', []):\n",
    "            cat_id = category.get('Category', 'N/A')\n",
    "            category_name = category.get('Category', 'Unknown Category')\n",
    "            category_description = category.get('Category_description', '')\n",
    "            \n",
    "            if include_category_description and category_description:\n",
    "                categories_details.append(f\" <Category class>:{cat_id}, <Category description>: {category_description}\")\n",
    "            else:\n",
    "                categories_details.append(f\" <Category class>:{cat_id}\")\n",
    "        \n",
    "        # Format the categories list\n",
    "        formatted_descriptions.append(f\"<Categories>: [{', '.join([category['Category'] for category in attribute.get('categories', [])])}]\")\n",
    "        \n",
    "        # Append detailed category descriptions\n",
    "        formatted_descriptions.extend(categories_details)\n",
    "        \n",
    "    return \"\\n\".join(formatted_descriptions)\n",
    "\n",
    "def format_attributes_to_json(json_file, image_id=\"image_id\"):\n",
    "    with open(json_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    formatted_data = {\"image_id\": image_id}\n",
    "    \n",
    "    for attribute in data[\"attributes\"]:\n",
    "        item_name = attribute.get('Item', 'Unknown Item')\n",
    "        categories = [category.get('Category', 'Unknown Category') for category in attribute.get('categories', [])]\n",
    "        formatted_data[item_name] = categories\n",
    "    \n",
    "    return json.dumps(formatted_data, indent=4)\n",
    "output_json = format_attributes_to_json(json_file)\n",
    "\n",
    "fields = [\n",
    "    \"image_id\",\n",
    "    \"Carriageway\",\n",
    "    \"Upgrade cost\",\n",
    "    \"Motorcycle observed flow\",\n",
    "    \"Bicycle observed flow\",\n",
    "    \"Pedestrian observed flow across the road\",\n",
    "    \"Pedestrian observed flow along the road driver-side\",\n",
    "    \"Pedestrian observed flow along the road passenger-side\",\n",
    "    \"Land use - driver-side\",\n",
    "    \"Land use - passenger-side\",\n",
    "    \"Area type\",\n",
    "    \"Speed limit\",\n",
    "    \"Motorcycle speed limit\",\n",
    "    \"Truck speed limit\",\n",
    "    \"Differential speed limits\",\n",
    "    \"Median type\",\n",
    "    \"Centreline rumble strips\",\n",
    "    \"Roadside severity - driver-side distance\",\n",
    "    \"Roadside severity - driver-side object\",\n",
    "    \"Roadside severity - passenger-side distance\",\n",
    "    \"Roadside severity - passenger-side object\",\n",
    "    \"Shoulder rumble strips\",\n",
    "    \"Paved shoulder - driver-side\",\n",
    "    \"Paved shoulder - passenger-side\",\n",
    "    \"Intersection type\",\n",
    "    \"Intersection channelisation\",\n",
    "    \"Intersecting road volume\",\n",
    "    \"Intersection quality\",\n",
    "    \"Property access points\",\n",
    "    \"Number of lanes\",\n",
    "    \"Lane width\",\n",
    "    \"Curvature\",\n",
    "    \"Quality of curve\",\n",
    "    \"Grade\",\n",
    "    \"Road condition\",\n",
    "    \"Skid resistance / grip\",\n",
    "    \"Delineation\",\n",
    "    \"Street lighting\",\n",
    "    \"Pedestrian crossing facilities - inspected road\",\n",
    "    \"Pedestrian crossing quality\",\n",
    "    \"Pedestrian crossing facilities - intersecting road\",\n",
    "    \"Pedestrian fencing\",\n",
    "    \"Speed management / traffic calming\",\n",
    "    \"Vehicle parking\",\n",
    "    \"Sidewalk - driver-side\",\n",
    "    \"Sidewalk - passenger-side\",\n",
    "    \"Service road\",\n",
    "    \"Facilities for motorised two wheelers\",\n",
    "    \"Facilities for bicycles\",\n",
    "    \"Roadworks\",\n",
    "    \"Sight distance\",\n",
    "    \"School zone warning\",\n",
    "    \"School zone crossing supervisor\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose image_id here\n",
    "This can be used for both ThaiRAP and Mapillary\n",
    "- ThaiRAP 2037 images\n",
    "- Mapillary 168 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the image ids\n",
    "choose_image_id = range(1, 2) # process image 1 to 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gemini configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = { \n",
    "    \"max_output_tokens\": 8192,\n",
    "    \"response_mime_type\": \"application/json\",\n",
    "    \"temperature\": 0,\n",
    "}\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    generation_config=generation_config,\n",
    "    system_instruction=f\"{prompt_instruction}\\n{json2text()}\\n\\n{output_format}\"\n",
    ")\n",
    "\n",
    "## Print below to check the instruction\n",
    "# print(f\"{prompt_instruction}\\n{json2text()}\\n\\n{output_format}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run to get the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image 1 - 1.jpg, token count:prompt_token_count: 26828\n",
      "candidates_token_count: 589\n",
      "total_token_count: 27417\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty DataFrame if the save file doesn't exist\n",
    "if not os.path.exists(save_path):\n",
    "    # Create a new DataFrame with the appropriate columns\n",
    "    output_df = pd.DataFrame(columns=fields)\n",
    "    output_df.to_csv(save_path, index=False)  # Save the new empty CSV with headers\n",
    "else:\n",
    "    # Load the existing file with keep_default_na=False to avoid converting empty strings to NaN\n",
    "    output_df = pd.read_csv(save_path, keep_default_na=False)\n",
    "\n",
    "# Process each image\n",
    "for image_id in choose_image_id:  # Adjust the range as necessary\n",
    "    image_file = f\"{image_id}.jpg\"\n",
    "    image_path = os.path.join(image_folder_path, image_file)\n",
    "    \n",
    "    # Randomly select an API key for this image processing\n",
    "    selected_api_key = random.choice(api_keys)\n",
    "    genai.configure(api_key=selected_api_key)\n",
    "\n",
    "    # Generate prompt for the current image\n",
    "    image_prompt = generate_single_image_prompt(image_id, df)\n",
    "    if image_prompt is None:\n",
    "        print(f\"Skipping image {image_id} - No data found in CSV\")\n",
    "        continue\n",
    "\n",
    "    # Open the image\n",
    "    image = PIL.Image.open(image_path)\n",
    "\n",
    "    response = model.generate_content([image, image_prompt])\n",
    "    response_text = response.text.strip()\n",
    "\n",
    "    # Process the response and handle retries\n",
    "    while len(json.loads(response_text)) != 53:\n",
    "        print(f\"There are: {len(json.loads(response_text))}\")\n",
    "        response = model.generate_content([image, image_prompt])\n",
    "        response_text = response.text.strip()\n",
    "\n",
    "    response_dict = json.loads(response_text)\n",
    "    df_result = pd.DataFrame.from_dict(response_dict, orient='index').transpose()\n",
    "    df_result = df_result.applymap(lambda x: x[0] if isinstance(x, list) and len(x) > 0 else x)\n",
    "\n",
    "\n",
    "    missing_cols = [col for col in fields if col not in df_result.columns]\n",
    "    for col in missing_cols:\n",
    "        df_result[col] = None  # or any default value\n",
    "\n",
    "    # Reorder the DataFrame to match the fields list\n",
    "    df_result = df_result[fields]\n",
    "    print(f\"Processed image {image_id} - {image_file}, token count:{response.usage_metadata}\")\n",
    "    # Append the new row to the existing DataFrame\n",
    "    output_df = pd.concat([output_df, df_result], ignore_index=True)\n",
    "\n",
    "    # Save the updated DataFrame back to the CSV after processing each image\n",
    "    output_df.to_csv(save_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
